{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RE50800 – Deep Learning-HW2",
   "id": "e474bba763370360"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Author: RE6121045 數據所碩一 侯登耀",
   "id": "33ed55d1379a97ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading Packages",
   "id": "37940eaf15bca41a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:38:57.093959Z",
     "start_time": "2024-06-20T00:38:55.016798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import cv2\n",
    "from fast_pytorch_kmeans import KMeans\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from joblib import dump, load\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "os.chdir(\"D:\\\\DY\\\\深度學習\\\\Assignment 2\\\\images\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "id": "d20c922df9be947f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reading Files and Images",
   "id": "cf3c65e4621c20a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:38:57.098600Z",
     "start_time": "2024-06-20T00:38:57.093959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_img(f):\n",
    "    f=open(f)\n",
    "    lines=f.readlines()\n",
    "    imgs, lab=[], []\n",
    "    for i in range(len(lines)):\n",
    "        fn, label = lines[i].split(' ')\n",
    "\n",
    "        im1=cv2.imread(fn)\n",
    "        im1=cv2.resize(im1, (124, 124), interpolation=cv2.INTER_AREA)\n",
    "        #===============================\n",
    "        #影像處理的技巧可以放這邊，來增強影像的品質\n",
    "        im1 = cv2.fastNlMeansDenoising(im1,None,3,7,21)\n",
    "        im1 = cv2.normalize(im1, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        #===============================\n",
    "        im1 = np.moveaxis(im1, 2, 0)\n",
    "        imgs.append(im1)\n",
    "        lab.append(int(label))\n",
    "\n",
    "    lab= np.asarray(lab, np.int32)\n",
    "    return imgs, lab "
   ],
   "id": "db02a4e18ad8d8b1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:38:57.103065Z",
     "start_time": "2024-06-20T00:38:57.099604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x, y = load_img('train.txt')\n",
    "# valx, valy = load_img('val.txt')\n",
    "# tx, ty = load_img('test.txt')\n",
    "\n",
    "# np.save('x.npy', x)            \n",
    "# np.save('y.npy', y)\n",
    "# np.save('tx.npy', tx)\n",
    "# np.save('ty.npy', ty)\n",
    "# np.save('valx.npy', valx)\n",
    "# np.save('valy.npy', valy) "
   ],
   "id": "cdd3ba6ab4139b02",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:38:57.820257Z",
     "start_time": "2024-06-20T00:38:57.104069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = np.load('./file/x.npy')\n",
    "y = np.load('./file/y.npy')\n",
    "valx = np.load('./file/valx.npy')\n",
    "valy = np.load('./file/valy.npy')\n",
    "tx = np.load('./file/tx.npy')\n",
    "ty = np.load('./file/ty.npy')"
   ],
   "id": "3f8e7891cdadab78",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T01:20:52.686692Z",
     "start_time": "2024-06-20T01:20:52.680655Z"
    }
   },
   "cell_type": "code",
   "source": "sum(y==7)",
   "id": "b59b10c4a7de2126",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1282"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T01:20:31.496694Z",
     "start_time": "2024-06-20T01:20:31.494585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(y))\n",
    "print(len(valy))\n",
    "print(len(ty))"
   ],
   "id": "e870c36f80327cdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63325\n",
      "450\n",
      "450\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.194165Z",
     "start_time": "2024-06-20T00:38:57.822262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the ImageNet-mini dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "x_tensor = torch.from_numpy(np.array(x)).float().to(device)\n",
    "y_tensor = torch.from_numpy(np.array(y)).long().to(device)\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "valx_tensor = torch.from_numpy(np.array(valx)).float().to(device)\n",
    "valy_tensor = torch.from_numpy(np.array(valy)).long().to(device)\n",
    "val_dataset = TensorDataset(valx_tensor, valy_tensor)\n",
    "\n",
    "tx_tensor = torch.from_numpy(np.array(tx)).float().to(device)\n",
    "ty_tensor = torch.from_numpy(np.array(ty)).long().to(device)\n",
    "t_dataset = TensorDataset(tx_tensor, ty_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "t_loader = DataLoader(t_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "9a6067a588350ba7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.211470Z",
     "start_time": "2024-06-20T00:39:00.194165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tx_tensor = torch.from_numpy(np.array(tx)).float().to(device)\n",
    "ty_tensor = torch.from_numpy(np.array(ty)).long().to(device)\n",
    "t_dataset = TensorDataset(tx_tensor, ty_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "t_loader = DataLoader(t_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "7f8d41e3851c4f7e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.214419Z",
     "start_time": "2024-06-20T00:39:00.211470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 提取單一通道\n",
    "R_channel = tx_tensor[:, 0:1, :, :]  # R 通道\n",
    "G_channel = tx_tensor[:, 1:2, :, :]  # G 通道\n",
    "B_channel = tx_tensor[:, 2:3, :, :]  # B 通道"
   ],
   "id": "49ffb555e48816b4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.239967Z",
     "start_time": "2024-06-20T00:39:00.214419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zero_channel = torch.zeros_like(R_channel)  # 用來填充的零通道\n",
    "\n",
    "# 保存單一通道組合，並用零填充其他兩個通道\n",
    "R_channel_pad = torch.cat((R_channel, zero_channel, zero_channel), dim=1)  # 只有 R\n",
    "G_channel_pad = torch.cat((zero_channel, G_channel, zero_channel), dim=1)  # 只有 G\n",
    "B_channel_pad = torch.cat((zero_channel, zero_channel, B_channel), dim=1) # 只有 B\n",
    "\n",
    "# 提取並組合雙通道，並用零填充缺失的通道\n",
    "RG_channel_pad  = torch.cat((R_channel, G_channel), dim=1) # RG 通道\n",
    "RB_channel_pad = torch.cat((R_channel, B_channel), dim=1) # RB 通道\n",
    "GB_channel_pad = torch.cat((G_channel, B_channel), dim=1)  # GB 通道\n"
   ],
   "id": "61d92d660e322f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.243803Z",
     "start_time": "2024-06-20T00:39:00.239967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_dataset_R = TensorDataset(R_channel, ty_tensor)\n",
    "t_dataset_G = TensorDataset(G_channel, ty_tensor)\n",
    "t_dataset_B = TensorDataset(B_channel, ty_tensor)\n",
    "t_dataset_RG = TensorDataset(RG_channel_pad, ty_tensor)\n",
    "t_dataset_RB = TensorDataset(RB_channel_pad, ty_tensor)\n",
    "t_dataset_GB = TensorDataset(GB_channel_pad, ty_tensor)\n",
    "\n",
    "t_loader_R = DataLoader(t_dataset_R , batch_size=32, shuffle=False)\n",
    "t_loader_G = DataLoader(t_dataset_G, batch_size=32, shuffle=False)\n",
    "t_loader_B = DataLoader(t_dataset_B, batch_size=32, shuffle=False)\n",
    "t_loader_RB = DataLoader(t_dataset_RB, batch_size=32, shuffle=False)\n",
    "t_loader_RG = DataLoader(t_dataset_RG, batch_size=32, shuffle=False)\n",
    "t_loader_GB = DataLoader(t_dataset_GB, batch_size=32, shuffle=False)"
   ],
   "id": "d0a11ea119d45061",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Problem 1.",
   "id": "2511a2b7082d8016"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.435345Z",
     "start_time": "2024-06-20T00:39:00.244806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio, K, temprature=30, init_weight=True):\n",
    "        super().__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.temprature = temprature\n",
    "        self.in_planes = in_planes  # 添加 in_planes 屬性\n",
    "        #assert in_planes > ratio\n",
    "        hidden_planes = in_planes // ratio\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, hidden_planes, kernel_size=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_planes, K, kernel_size=1, bias=False)\n",
    "        )\n",
    "\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def update_temprature(self):\n",
    "        if self.temprature > 1:\n",
    "            self.temprature -= 1\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        att = self.avgpool(x)  # bs, in_planes, 1, 1\n",
    "        att = self.net(att).view(x.shape[0], -1)  # bs, K\n",
    "        return F.softmax(att / self.temprature, -1)\n",
    "\n",
    "class VariableInputConv(nn.Module):\n",
    "    def __init__(self, out_planes, kernel_size, stride, padding=0, dilation=1, groups=1, bias=True, K=4, temprature=30, ratio=1):\n",
    "        super().__init__()\n",
    "        self.out_planes = out_planes\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.bias = bias\n",
    "        self.K = K\n",
    "        self.temprature = temprature\n",
    "        self.ratio = ratio\n",
    "\n",
    "        self.attention = None  # 會在 forward 中根據輸入大小動態初始化\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, in_planes, h, w = x.shape\n",
    "        device = x.device  # 獲取輸入張量的設備信息\n",
    "        \n",
    "        # 動態初始化或更新 Attention 模塊\n",
    "        if self.attention is None or self.attention.in_planes != in_planes:\n",
    "            self.attention = Attention(in_planes, self.ratio, self.K, self.temprature).to(device)  # 確保 Attention 在正確的設備上\n",
    "\n",
    "        # 確保 Attention 模塊的所有參數在正確的設備上\n",
    "        self.attention.to(device)\n",
    "\n",
    "        softmax_att = self.attention(x)  # bs, K\n",
    "\n",
    "        # 動態初始化權重，確保在正確的設備上\n",
    "        weight = torch.randn(self.K, self.out_planes, in_planes // self.groups, self.kernel_size, self.kernel_size, device=device)\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(weight[i])\n",
    "\n",
    "        aggregate_weight = torch.mm(softmax_att, weight.view(self.K, -1)).view(\n",
    "            bs * self.out_planes, in_planes // self.groups, self.kernel_size, self.kernel_size)\n",
    "\n",
    "        if self.bias:\n",
    "            bias = torch.randn(self.K, self.out_planes, device=device)\n",
    "            for i in range(self.K):\n",
    "                nn.init.constant_(bias[i], 0)\n",
    "            aggregate_bias = torch.mm(softmax_att, bias).view(-1)\n",
    "            output = F.conv2d(x.view(1, -1, h, w), weight=aggregate_weight, bias=aggregate_bias,\n",
    "                              stride=self.stride, padding=self.padding, groups=self.groups * bs, dilation=self.dilation)\n",
    "        else:\n",
    "            output = F.conv2d(x.view(1, -1, h, w), weight=aggregate_weight, bias=None,\n",
    "                              stride=self.stride, padding=self.padding, groups=self.groups * bs, dilation=self.dilation)\n",
    "\n",
    "        output = output.view(bs, self.out_planes, h, w)\n",
    "        return output\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# 測試 VariableInputConv 模塊\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    input = torch.randn(2, 32, 64, 64).to(device)  # 2 個樣本，每個樣本有 32 個通道，大小為 64x64\n",
    "    m = VariableInputConv(out_planes=64, kernel_size=3, stride=1, padding=1, bias=False).to(device)\n",
    "    out = m(input)\n",
    "    print(out.shape)\n",
    "    \n",
    "    input_var_channels = torch.randn(2, 48, 64, 64).to(device)  # 不同的輸入通道數量\n",
    "    out_var_channels = m(input_var_channels)\n",
    "    print(out_var_channels.shape)\n"
   ],
   "id": "d744e3cbb65e459b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 64, 64])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.439859Z",
     "start_time": "2024-06-20T00:39:00.435345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ],
   "id": "2421ab3edc7425a4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:00.446013Z",
     "start_time": "2024-06-20T00:39:00.440863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = VariableInputConv(out_planes=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "62548fab3f5231a4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:39:01.254422Z",
     "start_time": "2024-06-20T00:39:00.446013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dynamic_convolution_model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(dynamic_convolution_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# # Define a StepLR scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ],
   "id": "1abf1456bb23a662",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T01:04:47.326088Z",
     "start_time": "2024-06-20T00:39:01.254422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 30\n",
    "early_stopping_counter = 0\n",
    "best_val_acc = 0.0\n",
    "selected_channels = [0, 1, 2] \n",
    "\n",
    "# Lists to store loss and accuracy values\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    dynamic_convolution_model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backward pass\n",
    "        torch.nn.utils.clip_grad_norm_(dynamic_convolution_model.parameters(), max_norm=2.0)  # Gradient clipping\n",
    "        optimizer.step()  # Optimize the model\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    # Validation\n",
    "    dynamic_convolution_model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = dynamic_convolution_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total * 100\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}: Train Loss: {epoch_loss:.4f} Train Acc: {epoch_acc:.2f}% Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    if val_acc >= best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(dynamic_convolution_model.state_dict(), 'dynamic_convolution_model.pth')\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter > 5:  # Stops if no improvement after 4 epochs\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ],
   "id": "f62d363f02b784e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 3.7461 Train Acc: 5.36% Val Loss: 4.4855 Val Acc: 2.22%\n",
      "Epoch 2: Train Loss: 3.4972 Train Acc: 9.41% Val Loss: 4.4720 Val Acc: 1.56%\n",
      "Epoch 3: Train Loss: 3.2892 Train Acc: 13.25% Val Loss: 4.6039 Val Acc: 2.22%\n",
      "Epoch 4: Train Loss: 3.0792 Train Acc: 17.55% Val Loss: 4.4993 Val Acc: 4.89%\n",
      "Epoch 5: Train Loss: 2.8332 Train Acc: 22.42% Val Loss: 4.1665 Val Acc: 6.44%\n",
      "Epoch 6: Train Loss: 2.6367 Train Acc: 26.77% Val Loss: 4.4268 Val Acc: 5.33%\n",
      "Epoch 7: Train Loss: 2.4702 Train Acc: 30.64% Val Loss: 4.4763 Val Acc: 5.33%\n",
      "Epoch 8: Train Loss: 2.3387 Train Acc: 33.57% Val Loss: 4.4664 Val Acc: 9.11%\n",
      "Epoch 9: Train Loss: 2.2209 Train Acc: 36.04% Val Loss: 4.2024 Val Acc: 9.33%\n",
      "Epoch 10: Train Loss: 2.1183 Train Acc: 38.92% Val Loss: 3.7733 Val Acc: 10.44%\n",
      "Epoch 11: Train Loss: 2.0359 Train Acc: 40.73% Val Loss: 3.9856 Val Acc: 11.11%\n",
      "Epoch 12: Train Loss: 1.9617 Train Acc: 42.39% Val Loss: 3.7726 Val Acc: 13.11%\n",
      "Epoch 13: Train Loss: 1.8999 Train Acc: 44.21% Val Loss: 3.4381 Val Acc: 13.78%\n",
      "Epoch 14: Train Loss: 1.8400 Train Acc: 45.52% Val Loss: 3.5963 Val Acc: 13.78%\n",
      "Epoch 15: Train Loss: 1.7875 Train Acc: 46.70% Val Loss: 4.0443 Val Acc: 12.89%\n",
      "Epoch 16: Train Loss: 1.7382 Train Acc: 48.43% Val Loss: 3.7416 Val Acc: 16.00%\n",
      "Epoch 17: Train Loss: 1.6966 Train Acc: 49.29% Val Loss: 3.6386 Val Acc: 14.00%\n",
      "Epoch 18: Train Loss: 1.6647 Train Acc: 49.83% Val Loss: 3.4961 Val Acc: 13.11%\n",
      "Epoch 19: Train Loss: 1.6249 Train Acc: 51.07% Val Loss: 3.8249 Val Acc: 10.67%\n",
      "Epoch 20: Train Loss: 1.5927 Train Acc: 51.85% Val Loss: 3.7505 Val Acc: 14.89%\n",
      "Epoch 21: Train Loss: 1.5743 Train Acc: 52.39% Val Loss: 4.2606 Val Acc: 10.89%\n",
      "Epoch 22: Train Loss: 1.5407 Train Acc: 53.19% Val Loss: 3.5113 Val Acc: 17.56%\n",
      "Epoch 23: Train Loss: 1.5097 Train Acc: 54.04% Val Loss: 3.6929 Val Acc: 15.56%\n",
      "Epoch 24: Train Loss: 1.4930 Train Acc: 54.53% Val Loss: 4.0320 Val Acc: 12.67%\n",
      "Epoch 25: Train Loss: 1.4732 Train Acc: 55.05% Val Loss: 3.6137 Val Acc: 16.00%\n",
      "Epoch 26: Train Loss: 1.4552 Train Acc: 55.75% Val Loss: 3.6116 Val Acc: 17.78%\n",
      "Epoch 27: Train Loss: 1.4384 Train Acc: 55.92% Val Loss: 4.5153 Val Acc: 12.67%\n",
      "Epoch 28: Train Loss: 1.4256 Train Acc: 56.46% Val Loss: 3.6823 Val Acc: 18.44%\n",
      "Epoch 29: Train Loss: 1.4153 Train Acc: 56.60% Val Loss: 3.8979 Val Acc: 13.56%\n",
      "Epoch 30: Train Loss: 1.3967 Train Acc: 56.97% Val Loss: 3.6941 Val Acc: 16.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:42:29.586264Z",
     "start_time": "2024-06-20T08:42:29.410625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchprofile\n",
    "input = torch.randn(4, 3, 64, 64).to(device)\n",
    "# 計算參數數量\n",
    "num_params = count_parameters(dynamic_convolution_model)\n",
    "print(f\"Number of parameters: {num_params}\")\n",
    "\n",
    "# 使用 torchprofile 計算 FLOPs\n",
    "macs = torchprofile.profile_macs(dynamic_convolution_model, input)\n",
    "flops = macs * 2\n",
    "print(f\"FLOPs: {flops}\")\n",
    "\n",
    "input = torch.randn(1, 1, 64, 64).to(device)\n",
    "num_params = count_parameters(m)\n",
    "print(f\"Number of parameters: {num_params}\")\n",
    "\n",
    "# 使用 torchprofile 計算 FLOPs\n",
    "macs = torchprofile.profile_macs(m, input)\n",
    "flops = macs * 2\n",
    "print(f\"FLOPs: {flops}\")"
   ],
   "id": "9f85bfc998d2b285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 11192775\n",
      "FLOPs: 4492505282\n",
      "Number of parameters: 1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sljeng\\anaconda3\\Lib\\site-packages\\torchprofile\\profile.py:22: UserWarning: No handlers found: \"aten::randn\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "C:\\Users\\sljeng\\anaconda3\\Lib\\site-packages\\torchprofile\\profile.py:22: UserWarning: No handlers found: \"aten::uniform_\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "C:\\Users\\sljeng\\anaconda3\\Lib\\site-packages\\torchprofile\\profile.py:22: UserWarning: No handlers found: \"aten::mm\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Attention.__init__() takes 2 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[87], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_params\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# 使用 torchprofile 計算 FLOPs\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m macs \u001B[38;5;241m=\u001B[39m \u001B[43mtorchprofile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofile_macs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m flops \u001B[38;5;241m=\u001B[39m macs \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFLOPs: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mflops\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchprofile\\profile.py:12\u001B[0m, in \u001B[0;36mprofile_macs\u001B[1;34m(model, args, kwargs, reduction)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprofile_macs\u001B[39m(model, args\u001B[38;5;241m=\u001B[39m(), kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28msum\u001B[39m):\n\u001B[0;32m     10\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[1;32m---> 12\u001B[0m     graph \u001B[38;5;241m=\u001B[39m \u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mnodes:\n\u001B[0;32m     14\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m operators, func \u001B[38;5;129;01min\u001B[39;00m handlers:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchprofile\\utils\\trace.py:17\u001B[0m, in \u001B[0;36mtrace\u001B[1;34m(model, args, kwargs)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKeyword arguments are not supported for now. \u001B[39m\u001B[38;5;124m'\u001B[39m \\\n\u001B[0;32m     14\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPlease use positional arguments instead!\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings(record\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 17\u001B[0m     graph, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_trace_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mFlatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m graph\u001B[38;5;241m.\u001B[39mnodes():\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\jit\\_trace.py:1296\u001B[0m, in \u001B[0;36m_get_trace_graph\u001B[1;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001B[0m\n\u001B[0;32m   1294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(args, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m   1295\u001B[0m     args \u001B[38;5;241m=\u001B[39m (args,)\n\u001B[1;32m-> 1296\u001B[0m outs \u001B[38;5;241m=\u001B[39m \u001B[43mONNXTracedModule\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_return_inputs_states\u001B[49m\n\u001B[0;32m   1298\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outs\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\jit\\_trace.py:138\u001B[0m, in \u001B[0;36mONNXTracedModule.forward\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    136\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(out_vars)\n\u001B[1;32m--> 138\u001B[0m graph, out \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_by_tracing\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_vars\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_create_interpreter_name_lookup_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return_inputs:\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m graph, outs[\u001B[38;5;241m0\u001B[39m], ret_inputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\jit\\_trace.py:129\u001B[0m, in \u001B[0;36mONNXTracedModule.forward.<locals>.wrapper\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return_inputs_states:\n\u001B[0;32m    128\u001B[0m     inputs_states\u001B[38;5;241m.\u001B[39mappend(_unflatten(in_args, in_desc))\n\u001B[1;32m--> 129\u001B[0m outs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrace_inputs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return_inputs_states:\n\u001B[0;32m    131\u001B[0m     inputs_states[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m (inputs_states[\u001B[38;5;241m0\u001B[39m], trace_inputs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m         recording_scopes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1500\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1501\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1503\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchprofile\\utils\\flatten.py:29\u001B[0m, in \u001B[0;36mFlatten.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 29\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m flatten(outputs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m         recording_scopes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1500\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1501\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1503\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "Cell \u001B[1;32mIn[10], line 63\u001B[0m, in \u001B[0;36mVariableInputConv.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# 動態初始化或更新 Attention 模塊\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention\u001B[38;5;241m.\u001B[39min_planes \u001B[38;5;241m!=\u001B[39m in_planes:\n\u001B[1;32m---> 63\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention \u001B[38;5;241m=\u001B[39m \u001B[43mAttention\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_planes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mK\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtemprature\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)  \u001B[38;5;66;03m# 確保 Attention 在正確的設備上\u001B[39;00m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# 確保 Attention 模塊的所有參數在正確的設備上\u001B[39;00m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mTypeError\u001B[0m: Attention.__init__() takes 2 positional arguments but 5 were given"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T01:55:07.644305Z",
     "start_time": "2024-06-20T01:55:06.584428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dynamic_convolution_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader_R:\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the R test images: {100 * correct / total}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader_G:\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the G test images: {100 * correct / total}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader_B:\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the B test images: {100 * correct / total}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader_RG:\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the RG test images: {100 * correct / total}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader_RB:\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the RB test images: {100 * correct / total}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader_GB:\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the GB test images: {100 * correct / total}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader:\n",
    "        outputs = dynamic_convolution_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the RGB test images: {100 * correct / total}%\")"
   ],
   "id": "b127dcfe99075b08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the R test images: 18.666666666666668%\n",
      "Accuracy of the network on the G test images: 16.666666666666668%\n",
      "Accuracy of the network on the B test images: 15.703703703703704%\n",
      "Accuracy of the network on the RG test images: 16.055555555555557%\n",
      "Accuracy of the network on the RB test images: 15.6%\n",
      "Accuracy of the network on the GB test images: 15.222222222222221%\n",
      "Accuracy of the network on the RGB test images: 14.603174603174603%\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Problem 2.",
   "id": "49f593dafe5af393"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ResNet34 As Base Model",
   "id": "1e4050049f0f2c00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T07:47:52.973630Z",
     "start_time": "2024-06-20T07:47:52.789423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=50):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet34(num_classes=50):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "\n",
    "# base model\n",
    "base_model = resnet34(num_classes=50)\n",
    "print(base_model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "base_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(base_model.parameters(), lr=0.001)"
   ],
   "id": "21456f7bf212c6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
      ")\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:07:55.329272Z",
     "start_time": "2024-06-20T07:52:08.146263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    base_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = base_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        val_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    \n",
    "\n",
    "    # Validation loop\n",
    "    base_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = base_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}, Accuracy: {100 * correct / total}%\")\n"
   ],
   "id": "40dcfac99a1dac5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1.5834435136285678, Accuracy: 42.22222222222222%\n",
      "Epoch 2/30, Loss: 1.317062273267666, Accuracy: 46.0%\n",
      "Epoch 3/30, Loss: 1.0367319826497883, Accuracy: 47.55555555555556%\n",
      "Epoch 4/30, Loss: 0.7704049172788151, Accuracy: 48.22222222222222%\n",
      "Epoch 5/30, Loss: 0.5355785270459186, Accuracy: 49.111111111111114%\n",
      "Epoch 6/30, Loss: 0.3748383268021224, Accuracy: 52.22222222222222%\n",
      "Epoch 7/30, Loss: 0.2857163175291082, Accuracy: 48.44444444444444%\n",
      "Epoch 8/30, Loss: 0.2258533935338831, Accuracy: 48.0%\n",
      "Epoch 9/30, Loss: 0.201397883383432, Accuracy: 49.333333333333336%\n",
      "Epoch 10/30, Loss: 0.17580546241182082, Accuracy: 45.111111111111114%\n",
      "Epoch 11/30, Loss: 0.15533922311575532, Accuracy: 49.333333333333336%\n",
      "Epoch 12/30, Loss: 0.14495916267576475, Accuracy: 45.333333333333336%\n",
      "Epoch 13/30, Loss: 0.1317965313486337, Accuracy: 47.333333333333336%\n",
      "Epoch 14/30, Loss: 0.12498431376375901, Accuracy: 48.44444444444444%\n",
      "Epoch 15/30, Loss: 0.11272406381599138, Accuracy: 46.666666666666664%\n",
      "Epoch 16/30, Loss: 0.10744084251209003, Accuracy: 48.888888888888886%\n",
      "Epoch 17/30, Loss: 0.09768628812818107, Accuracy: 48.888888888888886%\n",
      "Epoch 18/30, Loss: 0.09434430901572473, Accuracy: 50.44444444444444%\n",
      "Epoch 19/30, Loss: 0.08789730511911396, Accuracy: 46.44444444444444%\n",
      "Epoch 20/30, Loss: 0.08425918619785865, Accuracy: 48.22222222222222%\n",
      "Epoch 21/30, Loss: 0.08220579958843899, Accuracy: 48.888888888888886%\n",
      "Epoch 22/30, Loss: 0.07775310693540953, Accuracy: 45.111111111111114%\n",
      "Epoch 23/30, Loss: 0.07118521314107273, Accuracy: 47.333333333333336%\n",
      "Epoch 24/30, Loss: 0.07353940114561053, Accuracy: 46.44444444444444%\n",
      "Epoch 25/30, Loss: 0.06755594112249133, Accuracy: 47.77777777777778%\n",
      "Epoch 26/30, Loss: 0.0635138992542085, Accuracy: 47.55555555555556%\n",
      "Epoch 27/30, Loss: 0.0672896057309529, Accuracy: 47.333333333333336%\n",
      "Epoch 28/30, Loss: 0.06312047466696294, Accuracy: 49.333333333333336%\n",
      "Epoch 29/30, Loss: 0.06140930022329444, Accuracy: 49.111111111111114%\n",
      "Epoch 30/30, Loss: 0.05866075507926655, Accuracy: 48.888888888888886%\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:09:59.845954Z",
     "start_time": "2024-06-20T08:09:59.843170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_losses[29])\n",
    "print(train_accuracies[29])"
   ],
   "id": "49956d1b97d5f855",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018332354410085826\n",
      "97.83339913146467\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T09:16:49.995917Z",
     "start_time": "2024-06-20T09:16:49.850389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchprofile\n",
    "input = torch.randn(1, 3, 64, 64).to(device) \n",
    "# 計算參數數量\n",
    "num_params = count_parameters(base_model)\n",
    "print(f\"Number of parameters: {num_params}\")\n",
    "\n",
    "# 使用 torchprofile 計算 FLOPs\n",
    "macs = torchprofile.profile_macs(base_model, input)\n",
    "flops = macs * 2\n",
    "print(f\"FLOPs: {flops}\")"
   ],
   "id": "f595bc06541f251",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 21310322\n",
      "FLOPs: 598744064\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:18:45.378242Z",
     "start_time": "2024-06-09T09:18:45.286594Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(base_model.state_dict(), \"assignment2_Q2_base_model.pth\")",
   "id": "ca2cb40cda6c0e19",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T11:49:43.520576Z",
     "start_time": "2024-06-19T11:49:43.507710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader:\n",
    "        outputs = base_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the 450 test images: {100 * correct / total}%\")"
   ],
   "id": "129a51b53039649",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mbase_model\u001B[49m\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m      2\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      3\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:26:17.024818Z",
     "start_time": "2024-06-20T08:26:16.761083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dcn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader:\n",
    "        outputs = base_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the 450 test images: {100 * correct / total}%\")"
   ],
   "id": "95a7ac2d6c4a3c65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 450 test images: 46.22222222222222%\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:10:29.454430Z",
     "start_time": "2024-06-20T08:10:29.343591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch\n",
    "import torchvision.ops\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class DeformableConv2d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 bias=False):\n",
    "        super(DeformableConv2d, self).__init__()\n",
    "\n",
    "        assert type(kernel_size) == tuple or type(kernel_size) == int\n",
    "\n",
    "        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n",
    "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.offset_conv = nn.Conv2d(in_channels,\n",
    "                                     2 * kernel_size[0] * kernel_size[1],\n",
    "                                     kernel_size=kernel_size,\n",
    "                                     stride=stride,\n",
    "                                     padding=self.padding,\n",
    "                                     dilation=self.dilation,\n",
    "                                     bias=True)\n",
    "\n",
    "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
    "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
    "\n",
    "        self.modulator_conv = nn.Conv2d(in_channels,\n",
    "                                        1 * kernel_size[0] * kernel_size[1],\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=stride,\n",
    "                                        padding=self.padding,\n",
    "                                        dilation=self.dilation,\n",
    "                                        bias=True)\n",
    "\n",
    "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
    "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
    "\n",
    "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=stride,\n",
    "                                      padding=self.padding,\n",
    "                                      dilation=self.dilation,\n",
    "                                      bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h, w = x.shape[2:]\n",
    "        # max_offset = max(h, w)/4.\n",
    "\n",
    "        offset = self.offset_conv(x)  # .clamp(-max_offset, max_offset)\n",
    "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
    "        # op = (n - (k * d - 1) + 2p / s)\n",
    "        x = torchvision.ops.deform_conv2d(input=x,\n",
    "                                          offset=offset,\n",
    "                                          weight=self.regular_conv.weight,\n",
    "                                          bias=self.regular_conv.bias,\n",
    "                                          padding=self.padding,\n",
    "                                          mask=modulator,\n",
    "                                          stride=self.stride,\n",
    "                                          dilation=self.dilation)\n",
    "        return x"
   ],
   "id": "36d35ae889ed9b43",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:10:32.251316Z",
     "start_time": "2024-06-20T08:10:32.241473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.ops\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeformableConv2d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 bias=False):\n",
    "        super(DeformableConv2d, self).__init__()\n",
    "\n",
    "        assert type(kernel_size) == tuple or type(kernel_size) == int\n",
    "\n",
    "        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n",
    "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.offset_conv = nn.Conv2d(in_channels,\n",
    "                                     2 * kernel_size[0] * kernel_size[1],\n",
    "                                     kernel_size=kernel_size,\n",
    "                                     stride=stride,\n",
    "                                     padding=self.padding,\n",
    "                                     dilation=self.dilation,\n",
    "                                     bias=True)\n",
    "\n",
    "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
    "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
    "\n",
    "        self.modulator_conv = nn.Conv2d(in_channels,\n",
    "                                        1 * kernel_size[0] * kernel_size[1],\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=stride,\n",
    "                                        padding=self.padding,\n",
    "                                        dilation=self.dilation,\n",
    "                                        bias=True)\n",
    "\n",
    "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
    "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
    "\n",
    "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=stride,\n",
    "                                      padding=self.padding,\n",
    "                                      dilation=self.dilation,\n",
    "                                      bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        offset = self.offset_conv(x)\n",
    "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
    "        x = torchvision.ops.deform_conv2d(input=x,\n",
    "                                          offset=offset,\n",
    "                                          weight=self.regular_conv.weight,\n",
    "                                          bias=self.regular_conv.bias,\n",
    "                                          padding=self.padding,\n",
    "                                          mask=modulator,\n",
    "                                          stride=self.stride,\n",
    "                                          dilation=self.dilation)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels // 8, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.attention(x)\n",
    "        return x * attention\n",
    "    \n",
    "    \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.sam = SAM(bias=False)\n",
    "        self.cam = CAM(channels=self.channels, r=self.r)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cam(x)\n",
    "        output = self.sam(output)\n",
    "        return output + x\n",
    "    \n",
    "    \n",
    "class CAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=self.channels, out_features=self.channels//self.r, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=self.channels//self.r, out_features=self.channels, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = F.adaptive_max_pool2d(x, output_size=1)\n",
    "        avg = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        b, c, _, _ = x.size()\n",
    "        linear_max = self.linear(max.view(b,c)).view(b, c, 1, 1)\n",
    "        linear_avg = self.linear(avg.view(b,c)).view(b, c, 1, 1)\n",
    "        output = linear_max + linear_avg\n",
    "        output = F.sigmoid(output) * x\n",
    "        return output\n",
    "    \n",
    "class SAM(nn.Module):\n",
    "    def __init__(self, bias=False):\n",
    "        super(SAM, self).__init__()\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = torch.max(x,1)[0].unsqueeze(1)\n",
    "        avg = torch.mean(x,1).unsqueeze(1)\n",
    "        concat = torch.cat((max,avg), dim=1)\n",
    "        output = self.conv(concat)\n",
    "        output = F.sigmoid(output) * x \n",
    "        return output "
   ],
   "id": "1450ebb67dd40e12",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:13:46.411947Z",
     "start_time": "2024-06-20T08:13:46.386338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(3, 64, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "        self.attention1 = Attention(64)\n",
    "        self.bn1 = nn.LayerNorm([64, 64, 64])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.layer2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn = nn.LayerNorm([64, 32, 32])\n",
    "        \n",
    "        self.layer3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.layer4 = DeformableConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.attention2 = CBAM(128, r=2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.bn2 = nn.LayerNorm([128, 32, 32])\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(128, 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.gelu(x) \n",
    "        x = self.attention1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.gelu(x) \n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.gelu(x) \n",
    "        x = self.attention2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Create a random tensor with the shape (batch_size, channels, height, width)\n",
    "\n",
    "# Initialize the model\n",
    "dcn_model = Classifier(num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(dcn_model.parameters(), lr=0.001)\n",
    "print(dcn_model)"
   ],
   "id": "7033c86e3c79b0b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (layer1): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (attention1): Attention(\n",
      "    (attention): Sequential(\n",
      "      (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (bn1): LayerNorm((64, 64, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn): LayerNorm((64, 32, 32), eps=1e-05, elementwise_affine=True)\n",
      "  (layer3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (layer4): DeformableConv2d(\n",
      "    (offset_conv): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (modulator_conv): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (regular_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (attention2): CBAM(\n",
      "    (sam): SAM(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (cam): CAM(\n",
      "      (linear): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn2): LayerNorm((128, 32, 32), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:13:49.562643Z",
     "start_time": "2024-06-20T08:13:49.553072Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "104fff725ea52fcc",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:23:18.011575Z",
     "start_time": "2024-06-20T08:13:52.699950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "save_dir = './model_checkpoints'  # Directory where model checkpoints will be saved\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    dcn_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = dcn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        val_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    # Validation loop\n",
    "    dcn_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = dcn_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print loss and accuracy\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}, Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    # Save model parameters\n",
    "    checkpoint_path = os.path.join(save_dir, f'model_epoch_{epoch + 1}.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,                     \n",
    "        'model_state_dict': dcn_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': running_loss / len(train_loader),\n",
    "        'accuracy': 100 * correct / total\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    print(f\"Model saved at {checkpoint_path}\")\n"
   ],
   "id": "10719ae9df4e46f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 3.3638417419609006, Accuracy: 18.22222222222222%\n",
      "Model saved at ./model_checkpoints\\model_epoch_1.pth\n",
      "Epoch 2/30, Loss: 2.870916064548155, Accuracy: 20.666666666666668%\n",
      "Model saved at ./model_checkpoints\\model_epoch_2.pth\n",
      "Epoch 3/30, Loss: 2.661215045826793, Accuracy: 28.22222222222222%\n",
      "Model saved at ./model_checkpoints\\model_epoch_3.pth\n",
      "Epoch 4/30, Loss: 2.522314536565479, Accuracy: 27.77777777777778%\n",
      "Model saved at ./model_checkpoints\\model_epoch_4.pth\n",
      "Epoch 5/30, Loss: 2.411317072533911, Accuracy: 32.666666666666664%\n",
      "Model saved at ./model_checkpoints\\model_epoch_5.pth\n",
      "Epoch 6/30, Loss: 2.3212589815808644, Accuracy: 34.666666666666664%\n",
      "Model saved at ./model_checkpoints\\model_epoch_6.pth\n",
      "Epoch 7/30, Loss: 2.2436112280503977, Accuracy: 33.55555555555556%\n",
      "Model saved at ./model_checkpoints\\model_epoch_7.pth\n",
      "Epoch 8/30, Loss: 2.187019668124191, Accuracy: 33.77777777777778%\n",
      "Model saved at ./model_checkpoints\\model_epoch_8.pth\n",
      "Epoch 9/30, Loss: 2.1301817713270528, Accuracy: 36.666666666666664%\n",
      "Model saved at ./model_checkpoints\\model_epoch_9.pth\n",
      "Epoch 10/30, Loss: 2.0748831462595065, Accuracy: 38.44444444444444%\n",
      "Model saved at ./model_checkpoints\\model_epoch_10.pth\n",
      "Epoch 11/30, Loss: 2.032774451346395, Accuracy: 36.888888888888886%\n",
      "Model saved at ./model_checkpoints\\model_epoch_11.pth\n",
      "Epoch 12/30, Loss: 1.9966782205571063, Accuracy: 40.44444444444444%\n",
      "Model saved at ./model_checkpoints\\model_epoch_12.pth\n",
      "Epoch 13/30, Loss: 1.9443993462403053, Accuracy: 41.77777777777778%\n",
      "Model saved at ./model_checkpoints\\model_epoch_13.pth\n",
      "Epoch 14/30, Loss: 1.9092674093935573, Accuracy: 40.0%\n",
      "Model saved at ./model_checkpoints\\model_epoch_14.pth\n",
      "Epoch 15/30, Loss: 1.879179311557633, Accuracy: 41.55555555555556%\n",
      "Model saved at ./model_checkpoints\\model_epoch_15.pth\n",
      "Epoch 16/30, Loss: 1.8660371128870659, Accuracy: 44.888888888888886%\n",
      "Model saved at ./model_checkpoints\\model_epoch_16.pth\n",
      "Epoch 17/30, Loss: 1.8380008266091408, Accuracy: 43.77777777777778%\n",
      "Model saved at ./model_checkpoints\\model_epoch_17.pth\n",
      "Epoch 18/30, Loss: 1.8114017475247683, Accuracy: 40.888888888888886%\n",
      "Model saved at ./model_checkpoints\\model_epoch_18.pth\n",
      "Epoch 19/30, Loss: 1.7901117361633991, Accuracy: 43.77777777777778%\n",
      "Model saved at ./model_checkpoints\\model_epoch_19.pth\n",
      "Epoch 20/30, Loss: 1.7803740997456612, Accuracy: 44.22222222222222%\n",
      "Model saved at ./model_checkpoints\\model_epoch_20.pth\n",
      "Epoch 21/30, Loss: 1.7489615014974007, Accuracy: 40.888888888888886%\n",
      "Model saved at ./model_checkpoints\\model_epoch_21.pth\n",
      "Epoch 22/30, Loss: 1.7403972289247787, Accuracy: 47.111111111111114%\n",
      "Model saved at ./model_checkpoints\\model_epoch_22.pth\n",
      "Epoch 23/30, Loss: 1.7139580135637007, Accuracy: 44.22222222222222%\n",
      "Model saved at ./model_checkpoints\\model_epoch_23.pth\n",
      "Epoch 24/30, Loss: 1.7289194584254246, Accuracy: 37.55555555555556%\n",
      "Model saved at ./model_checkpoints\\model_epoch_24.pth\n",
      "Epoch 25/30, Loss: 1.7000192800756053, Accuracy: 43.333333333333336%\n",
      "Model saved at ./model_checkpoints\\model_epoch_25.pth\n",
      "Epoch 26/30, Loss: 1.6856548998800416, Accuracy: 45.111111111111114%\n",
      "Model saved at ./model_checkpoints\\model_epoch_26.pth\n",
      "Epoch 27/30, Loss: 1.6707070772849049, Accuracy: 41.111111111111114%\n",
      "Model saved at ./model_checkpoints\\model_epoch_27.pth\n",
      "Epoch 28/30, Loss: 1.6569850673995998, Accuracy: 42.0%\n",
      "Model saved at ./model_checkpoints\\model_epoch_28.pth\n",
      "Epoch 29/30, Loss: 1.6492726839871765, Accuracy: 41.55555555555556%\n",
      "Model saved at ./model_checkpoints\\model_epoch_29.pth\n",
      "Epoch 30/30, Loss: 1.6458791955183587, Accuracy: 46.888888888888886%\n",
      "Model saved at ./model_checkpoints\\model_epoch_30.pth\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:27:35.888264Z",
     "start_time": "2024-06-20T08:27:35.882898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_losses[29])\n",
    "print(train_accuracies[29])"
   ],
   "id": "a011817fbb0f24b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051436161514896675\n",
      "50.55665219107778\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T06:09:43.862003Z",
     "start_time": "2024-06-09T06:09:43.851704Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(dcn_model.state_dict(), \"assignment2_Q2_model.pth\")",
   "id": "55cb705a0ac9bd28",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T09:17:55.981415Z",
     "start_time": "2024-06-20T09:17:55.941152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchprofile\n",
    "input = torch.randn(1, 3, 128, 128).to(device) \n",
    "# 計算參數數量\n",
    "num_params = count_parameters(dcn_model)\n",
    "print(f\"Number of parameters: {num_params}\")\n",
    "\n",
    "# 使用 torchprofile 計算 FLOPs\n",
    "macs = torchprofile.profile_macs(dcn_model, input)\n",
    "flops = macs * 2\n",
    "print(f\"FLOPs: {flops}\")"
   ],
   "id": "3baa3026e9996e40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1109879\n",
      "FLOPs: 232821760\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T08:25:57.831053Z",
     "start_time": "2024-06-20T08:25:57.474051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dcn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in t_loader:\n",
    "        outputs = dcn_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print loss and accuracy\n",
    "print(f\"Accuracy of the network on the 450 test images: {100 * correct / total}%\")"
   ],
   "id": "9fc5e7a36616a34a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 450 test images: 46.22222222222222%\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dcn_model = torch.load(\"assignment2_Q2_model.pth\")",
   "id": "3fd70824a9ecc901"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
